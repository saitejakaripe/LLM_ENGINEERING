{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0e11f2-9ea4-48c2-b8d2-d0a4ba967827",
   "metadata": {},
   "source": [
    "# Gradio Day!\n",
    "\n",
    "Today we will build User Interfaces using the outrageously simple Gradio framework.\n",
    "\n",
    "Prepare for joy!\n",
    "\n",
    "Please note: your Gradio screens may appear in 'dark mode' or 'light mode' depending on your computer settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44c5494-950d-4d2f-8d4f-b87b57c5b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1715421-cead-400b-99af-986388a97aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # oh yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337d5dfc-0181-4e3b-8ab9-e78e0c3f657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set\n",
      "Google API Key exists and begins AIzaSyCt\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "# You can choose whichever providers you like - or all Ollama\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22586021-1795-4929-8079-63f5bb4edd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ef9b69-ef31-427d-86d0-b8c799e1c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4.1-mini in a simple function\n",
    "\n",
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef7d314-2b13-436b-b02d-8de3b72b193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is June 13, 2024.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can reveal the \"training cut off\", or the most recent date in the training data\n",
    "\n",
    "message_gpt(\"What is today's date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94013d1-4f27-4329-97e8-8c58db93636a",
   "metadata": {},
   "source": [
    "## User Interface time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc664b7a-c01d-4fea-a1de-ae22cdd5141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a simple function\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977bb496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ea451-d3a0-4d13-b599-93ed49b975e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/744225371.py:1: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Shout has been called with input hello\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a359a4-685c-4c99-891c-bb4d1cb7f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/1623918000.py:6: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://620e379b8abeac1c35.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://620e379b8abeac1c35.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input hi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd87533a-ff3a-4188-8998-5bedd5ba2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/3948271144.py:3: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# Adding inbrowser=True opens up a new browser window automatically\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42945b17",
   "metadata": {},
   "source": [
    "## Adding authentication\n",
    "\n",
    "Gradio makes it very easy to have userids and passwords\n",
    "\n",
    "Obviously if you use this, have it look properly in a secure place for passwords! At a minimum, use your .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c34e6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/3989119055.py:1: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True, auth=(\"ed\", \"bananas\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True, auth=(\"ed\", \"bananas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8129afa-532b-4b15-b93c-aa9cca23a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/212800645.py:12: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never', 'js': \"\\nfunction refresh() {\\n    const url = new URL(window.location);\\n    if (url.searchParams.get('__theme') !== 'dark') {\\n        url.searchParams.set('__theme', 'dark');\\n        window.location.href = url.href;\\n    }\\n}\\n\"}\n",
      "  gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Shout has been called with input hello\n"
     ]
    }
   ],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc67b26-dd5f-406d-88f6-2306ee2950c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/475100892.py:6: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Shout has been called with input hello\n"
     ]
    }
   ],
   "source": [
    "# Adding a little more:\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message to be shouted\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    title=\"Shout\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f235288e-63a2-4341-935b-1441f9be969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/2142471093.py:6: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# And now - changing the function from \"shout\" to \"message_gpt\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9a3262-e626-4e4b-80b0-aca152405e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/22998752.py:11: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# Let's use Markdown\n",
    "# Are you wondering why it makes any difference to set system_message when it's not referred to in the code below it?\n",
    "# I'm taking advantage of system_message being a global variable, used back in the message_gpt function (go take a look)\n",
    "# Not a great software engineering practice, but quite common during Jupyter Lab R&D!\n",
    "\n",
    "system_message = \"You are a helpful assistant that responds in markdown without code blocks\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c04ebf-0671-4fea-95c9-bc1565d4bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a call that streams back results\n",
    "# If you'd like a refresher on Generators (the \"yield\" keyword),\n",
    "# Please take a look at the Intermediate Python guide in the guides folder\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc47b36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/529568244.py:1: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    title=\"GPT\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "view.queue()          # ðŸ‘ˆ enable queue for streaming\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d87d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gemini(prompt: str):\n",
    "    # Build conversation for Gemini\n",
    "    contents = [\n",
    "        # System-style instruction (first message)\n",
    "        {\"role\": \"user\", \"parts\": [{\"text\": system_message}]},\n",
    "        # Actual user question\n",
    "        {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "    ]\n",
    "\n",
    "    # Streaming call\n",
    "    stream = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",   # or any Gemini model you prefer\n",
    "        contents=contents,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        # Each chunk has partial text\n",
    "        text = getattr(chunk, \"text\", \"\") or \"\"\n",
    "        result += text\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a43d99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/79394795.py:8: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 407, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1550, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1199, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 519, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 512, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 495, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/udaykumar/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 649, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/995821638.py\", line 11, in stream_gemini\n",
      "    stream = gemini_client.models.generate_content(\n",
      "             ^^^^^^^^^^^^^\n",
      "NameError: name 'gemini_client' is not defined\n"
     ]
    }
   ],
   "source": [
    "message_input = gr.Textbox(\n",
    "    label=\"Your message:\",\n",
    "    info=\"Enter a message for Gemini 2.5 Flash Lite\",\n",
    "    lines=7,\n",
    ")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_gemini,\n",
    "    title=\"Gemini\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "# Needed for streaming (since stream_gemini uses yield)\n",
    "view.queue()\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e81f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from google import genai\n",
    "\n",
    "# Gemini client (needs GOOGLE_API_KEY in your environment)\n",
    "gemini_client = genai.Client()\n",
    "\n",
    "system_message = (\n",
    "    \"You are a helpful, polite AI assistant. \"\n",
    "    \"Explain things clearly and concisely in simple language.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c689828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gemini(prompt: str) -> str:\n",
    "    # Build conversation for Gemini\n",
    "    contents = [\n",
    "        # \"System\" behaviour as an initial user-style message\n",
    "        {\"role\": \"user\", \"parts\": [{\"text\": system_message}]},\n",
    "        # Actual user question\n",
    "        {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "    ]\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",   # or any Gemini model you have access to\n",
    "        contents=contents,\n",
    "    )\n",
    "\n",
    "    # google-genai returns the full text here\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04106aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/497051927.py:9: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "message_input = gr.Textbox(\n",
    "    label=\"Your message:\",\n",
    "    info=\"Enter a message for Gemini 2.5 Flash Lite\",\n",
    "    lines=7,\n",
    ")\n",
    "\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=chat_gemini,\n",
    "    title=\"Gemini\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a70b9-2afe-4a7c-9bed-2429229e021b",
   "metadata": {},
   "source": [
    "## And now getting fancy\n",
    "\n",
    "Remember to check the Intermediate Python Guide if you're unsure about generators and \"yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7524b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model == \"GPT\":\n",
    "        # stream_gpt is already a generator â†’ just forward its chunks\n",
    "        for partial in stream_gpt(prompt):\n",
    "            yield partial\n",
    "\n",
    "    elif model == \"Gemini\":\n",
    "        # chat_gemini returns the full text once\n",
    "        text = chat_gemini(prompt)\n",
    "        yield text\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ecae4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/1348369385.py:15: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "message_input = gr.Textbox(\n",
    "    label=\"Your message:\",\n",
    "    info=\"Enter a message for the LLM\",\n",
    "    lines=7,\n",
    ")\n",
    "\n",
    "model_selector = gr.Dropdown(\n",
    "    [\"GPT\", \"Gemini\"],          # ðŸ‘ˆ swapped Claude â†’ Gemini\n",
    "    label=\"Select model\",\n",
    "    value=\"GPT\",\n",
    ")\n",
    "\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    title=\"LLMs\",\n",
    "    inputs=[message_input, model_selector],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        [\"Explain the Transformer architecture to a layperson\", \"GPT\"],\n",
    "        [\"Explain the Transformer architecture to an aspiring AI engineer\", \"Gemini\"],\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "# because stream_model uses yield\n",
    "view.queue()\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1626eb2e-eee8-4183-bda5-1591b58ae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import fetch_website_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c701ec17-ecd5-4000-9f68-34634c8ed49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Again this is typical Experimental mindset - I'm changing the global variable we used above:\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an assistant that analyzes the contents of a company website landing page\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1508f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    # optional: immediately clear / show something\n",
    "    yield \"\"\n",
    "\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += fetch_website_contents(url)\n",
    "\n",
    "    if model == \"GPT\":\n",
    "        # stream_gpt is already a generator â†’ forward chunks\n",
    "        result_stream = stream_gpt(prompt)\n",
    "        yield from result_stream\n",
    "\n",
    "    elif model == \"Gemini\":\n",
    "        # chat_gemini returns full text once â†’ yield it as a single chunk\n",
    "        text = chat_gemini(prompt)\n",
    "        yield text\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fcc5d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/19d9_8q942g8jc86b9yk5sfw0000gn/T/ipykernel_28088/3962812450.py:12: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'flagging_mode': 'never'}\n",
      "  view = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "name_input = gr.Textbox(label=\"Company name:\")\n",
    "url_input = gr.Textbox(label=\"Landing page URL including http:// or https://\")\n",
    "\n",
    "model_selector = gr.Dropdown(\n",
    "    [\"GPT\", \"Gemini\"],          # ðŸ‘ˆ replaced Claude with Gemini\n",
    "    label=\"Select model\",\n",
    "    value=\"GPT\",\n",
    ")\n",
    "\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    title=\"Brochure Generator\",\n",
    "    inputs=[name_input, url_input, model_selector],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        [\"Hugging Face\", \"https://huggingface.co\", \"GPT\"],\n",
    "        [\"Edward Donner\", \"https://edwarddonner.com\", \"Gemini\"],   # ðŸ‘ˆ updated label\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "# because stream_brochure uses `yield`\n",
    "view.queue()\n",
    "view.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
