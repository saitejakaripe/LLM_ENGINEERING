{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60995166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbcfcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = test.load_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4d88a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65fd09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who won the prestigious IIOTY award in 2023?\n",
      "direct_fact\n",
      "Maxine Thompson won the prestigious Insurellm Innovator of the Year (IIOTY) award in 2023.\n",
      "['Maxine', 'Thompson', 'IIOTY']\n"
     ]
    }
   ],
   "source": [
    "example = tests[0]\n",
    "print(example.question)\n",
    "print(example.category)\n",
    "print(example.reference_answer)\n",
    "print(example.keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f058ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'direct_fact': 70,\n",
       "         'temporal': 20,\n",
       "         'spanning': 20,\n",
       "         'comparative': 10,\n",
       "         'numerical': 10,\n",
       "         'relationship': 10,\n",
       "         'holistic': 10})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter([t.category for t in tests])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b413b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.eval import evaluate_retrieval, evaluate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalEval(mrr=0.16666666666666666, ndcg=0.29420493957109245, keywords_found=2, total_keywords=3, keyword_coverage=66.66666666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_retrieval(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925b37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval, answer, chunks = evaluate_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01965312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerEval(feedback=\"The answer correctly identifies Maxine as the winner and the award as IIOTY, matching the reference answer. However, it introduces a different full name, 'Maxine,' whereas the reference specifies 'Maxine Thompson.' It also abbreviates 'Insurellm Innovator of the Year' as 'Insurellm' without the full name, which differs from the reference. Despite these discrepancies, the core information is accurate.\", accuracy=4.0, completeness=4.0, relevance=5.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd34561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer correctly identifies Maxine as the winner and the award as IIOTY, matching the reference answer. However, it introduces a different full name, 'Maxine,' whereas the reference specifies 'Maxine Thompson.' It also abbreviates 'Insurellm Innovator of the Year' as 'Insurellm' without the full name, which differs from the reference. Despite these discrepancies, the core information is accurate.\n",
      "4.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(eval.feedback)\n",
    "print(eval.accuracy)\n",
    "print(eval.completeness)\n",
    "print(eval.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e0cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
